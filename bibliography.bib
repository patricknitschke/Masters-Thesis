%
%
% INTRODUCTION 
%
%

%
%
% THEORY
%
%

%
%
% RELATED WORKS
%
%
@article{LearningStateRepresentation,
  author    = {David Hoeller and
               Lorenz Wellhausen and
               Farbod Farshidian and
               Marco Hutter},
  title     = {Learning a State Representation and Navigation in Cluttered and Dynamic
               Environments},
  journal   = {CoRR},
  volume    = {abs/2103.04351},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.04351},
  eprinttype = {arXiv},
  eprint    = {2103.04351},
  timestamp = {Mon, 15 Mar 2021 17:30:55 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-04351.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{LearningWalkMassivelyParallel,
  author    = {Nikita Rudin and
               David Hoeller and
               Philipp Reist and
               Marco Hutter},
  title     = {Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/2109.11978},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.11978},
  eprinttype = {arXiv},
  eprint    = {2109.11978},
  timestamp = {Mon, 27 Sep 2021 15:21:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2109-11978.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{NavRep_unsupervised,
  author    = {Daniel Dugas and
               Juan I. Nieto and
               Roland Siegwart and
               Jen Jen Chung},
  title     = {NavRep: Unsupervised Representations for Reinforcement Learning of
               Robot Navigation in Dynamic Human Environments},
  journal   = {CoRR},
  volume    = {abs/2012.04406},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.04406},
  eprinttype = {arXiv},
  eprint    = {2012.04406},
  timestamp = {Sat, 23 Jan 2021 17:33:04 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-04406.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{HighSpeedFlightWild,
  author    = {Antonio Loquercio and
               Elia Kaufmann and
               Ren{\'{e}} Ranftl and
               Matthias M{\"{u}}ller and
               Vladlen Koltun and
               Davide Scaramuzza},
  title     = {Learning High-Speed Flight in the Wild},
  journal   = {CoRR},
  volume    = {abs/2110.05113},
  year      = {2021},
  url       = {https://arxiv.org/abs/2110.05113},
  eprinttype = {arXiv},
  eprint    = {2110.05113},
  timestamp = {Thu, 21 Oct 2021 16:20:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2110-05113.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%
% IMPLEMENTATION
%
@article{IsaacGym,
  author    = {Viktor Makoviychuk and
               Lukasz Wawrzyniak and
               Yunrong Guo and
               Michelle Lu and
               Kier Storey and
               Miles Macklin and
               David Hoeller and
               Nikita Rudin and
               Arthur Allshire and
               Ankur Handa and
               Gavriel State},
  title     = {Isaac Gym: High Performance GPU-Based Physics Simulation For Robot
               Learning},
  journal   = {CoRR},
  volume    = {abs/2108.10470},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.10470},
  eprinttype = {arXiv},
  eprint    = {2108.10470},
  timestamp = {Fri, 27 Aug 2021 15:02:29 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2108-10470.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
% weight initialisation for layers with ReLU, necessary to conver 
@article{RectifiersKaimingHe2015,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on
               ImageNet Classification},
  journal   = {CoRR},
  volume    = {abs/1502.01852},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.01852},
  eprinttype = {arXiv},
  eprint    = {1502.01852},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZR015.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%
%
% EVALUATION STUDIES 
%
%






































%
%
% INTRODUCTION 
%
%

@online{washingtonPost, 
    title={Inside the Pentagon's \$82 million Super Bowl of robots}, url={https://www.washingtonpost.com/magazine/2021/11/10/darpa-robot-competition/}, journal={The Washington Post}, publisher={WP Company}, author={Montgomery, David}, year={2021}, month={11},
}
@misc{Gartner, 
     title={Gartner Hype Cycle Research Methodology}, url={https://www.gartner.com/en/research/methodologies/gartner-hype-cycle}, journal={Gartner}, author={{Gartner, Inc.}}
} 
@ARTICLE{MultirotorAerialVehicles,
    author={Mahony, Robert and Kumar, Vijay and Corke, Peter},
    journal={IEEE Robotics   Automation Magazine}, 
    title={Multirotor Aerial Vehicles: Modeling, Estimation, and Control of Quadrotor},
    year={2012},
    volume={19},
    number={3},
    pages={20-32},
    doi={10.1109/MRA.2012.2206474}
}
@misc{TTK23,
  author        = {Lekkas, Anastasios},
  title         = {Introduction to Autonomous Robotic Systems for Industry 4.0, Lecture notes},
  month         = {10},
  year          = {2021},
  publisher={Norwegian University of Science and Technology}
}
@misc{openAIgym,
      title={OpenAI Gym}, 
      author={Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
      year={2016},
      eprint={1606.01540},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@online{eelumeSale, 
    title={Argeo has signed the first commercial contract for Eelume's snake robot technology.}, url={https://www.kongsberg.com/maritime/about-us/news-and-media/news-archive/2021/argeo-chooses-kongsberg-maritime-supported--eelume/}, journal={Argeo has signed the first commercial contract for Eelume's snake robot technology. - Kongsberg Maritime}, author={Group, Kongsberg}, year={2021}, month={11}
}
@online{reasearchGrant,
    title={How to win a research grant}, url={https://www.timeshighereducation.com/features/how-win-research-grant}, journal={Times Higher Education (THE)}, author={Seeliger, Jessica and Ankeny, Rachel and Contributors and Pells, Rachael and Reisz, Matthew and Ross, John and Havergal, Chris and Upton, Ben}, year={2020}, month={3}
}
@online{roboticsMarket,
    title={Robotics Market: Global Industry Trends, Share, Size, Growth, Opportunity and Forecast 2021-2026}, url={https://www.imarcgroup.com/robotics-market}, journal={Size, Trends, Report and Forecast 2021-2026}, urldate={2021-11-13}
}
@article{Gullapalli1994,
    author = {Gullapalli, Vijaykumar and Franklin, Judy and Benbrahim, Hamid},
    year = {1994},
    month = {3},
    pages = {13 - 24},
    title = {Acquiring Robot Skills via Reinforcement Learning},
    volume = {14},
    journal = {Control Systems, IEEE},
    doi = {10.1109/37.257890}
}
@article{Miyamoto1996,
	title = {A Kendama Learning Robot Based on Bi-directional Theory},
	journal = {Neural Networks},
	volume = {9},
	number = {8},
	pages = {1281-1302},
	year = {1996},
	note = {Four Major Hypotheses in Neuroscience},
	issn = {0893-6080},
	doi = {https://doi.org/10.1016/S0893-6080(96)00043-3},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608096000433},
	author = {Hiroyuki Miyamoto and Stefan Schaal and Francesca Gandolfo and Hiroaki Gomi and Yasuharu Koike and Rieko Osu and Eri Nakano and Yasuhiro Wada and Mitsuo Kawato},
}
@misc{ppoOnDota2020,
      title={Dota 2 with Large Scale Deep Reinforcement Learning}, 
      author={OpenAI and : and Christopher Berner and Greg Brockman and Brooke Chan and Vicki Cheung and Przemysław Dębiak and Christy Dennison and David Farhi and Quirin Fischer and Shariq Hashme and Chris Hesse and Rafal Józefowicz and Scott Gray and Catherine Olsson and Jakub Pachocki and Michael Petrov and Henrique P. d. O. Pinto and Jonathan Raiman and Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and Filip Wolski and Susan Zhang},
      year={2019},
      eprint={1912.06680},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@online{alphaGo2015, 
    title={AlphaGo: The story so far}, url={https://deepmind.com/research/case-studies/alphago-the-story-so-far}, journal={Deepmind},
    urldate={2021-11-13}
}
@article{mnih2013Atari,
      title={Playing Atari with Deep Reinforcement Learning}, 
      author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
      year={2013},
      eprint={1312.5602},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{AlexNet2012,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}
@article{RodriguezRamos2019ADR,
  title={A Deep Reinforcement Learning Strategy for UAV Autonomous Landing on a Moving Platform},
  author={Alejandro Rodriguez-Ramos and Carlos Sampedro and Hriday Bavle and Paloma de la Puente and Pascual Campoy},
  journal={Journal of Intelligent \& Robotic Systems},
  year={2019},
  volume={93},
  pages={351-366}
}
@article{ControlofQuadrotorRL,
   title={Control of a Quadrotor With Reinforcement Learning},
   volume={2},
   ISSN={2377-3774},
   url={http://dx.doi.org/10.1109/LRA.2017.2720851},
   DOI={10.1109/lra.2017.2720851},
   number={4},
   journal={IEEE Robotics and Automation Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Hwangbo, Jemin and Sa, Inkyu and Siegwart, Roland and Hutter, Marco},
   year={2017},
   month={10},
   pages={2096–2103}
}
@inproceedings{PPOQuadrotor,
    author = {Lopes, Guilherme and Ferreira, Murillo and Simões, Alexandre and Colombini, Esther},
    year = {2018},
    month = {11},
    pages = {503-508},
    title = {Intelligent Control of a Quadrotor with Proximal Policy Optimization Reinforcement Learning},
    doi = {10.1109/LARS/SBR/WRE.2018.00094}
}
@article{Roy2002MotionPT,
    title={Motion planning through policy search},
    author={Nicholas Roy and Sebastian Thrun},
    journal={IEEE/RSJ International Conference on Intelligent Robots and Systems},
    year={2002},
    volume={3},
    pages={2419-2424 vol.3}
}
@article{song2021droneRacing,
    title={Autonomous Drone Racing with Deep Reinforcement Learning}, 
    author={Yunlong Song and Mats Steinweg and Elia Kaufmann and Davide Scaramuzza},
    year={2021},
    eprint={2103.08624},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}



%
%
% BACKGROUND
%
%

@book{suttonAndBartoBook,
    title={Reinforcement learning: An introduction},
    author={Sutton, Richard S and Barto, Andrew G},
    year={2018},
    publisher={MIT press}
}
@book{BellmanDreyfus1962Book,
  added-at = {2009-08-29T18:11:31.000+0200},
  author = {Bellman, Richard E. and Dreyfus, Stuart E.},
  biburl = {https://www.bibsonomy.org/bibtex/2fa909beda447178933154398d56b3e6c/n770},
  interhash = {7d5eea82dd3da41480fe7fee1767e908},
  intrahash = {fa909beda447178933154398d56b3e6c},
  keywords = {imported},
  publisher = {Princetown University Press},
  timestamp = {2009-08-29T18:12:13.000+0200},
  title = {{Applied Dynamic Programming}},
  year = 1962
}
@article{RLinRoboticsSurvey,
    author = {Kober, Jens and Bagnell, J. and Peters, Jan},
    year = {2013},
    month = {09},
    pages = {1238-1274},
    title = {Reinforcement Learning in Robotics: A Survey},
    volume = {32},
    isbn = {978-3-642-27644-6},
    journal = {The International Journal of Robotics Research},
    doi = {10.1177/0278364913495721}
}
@article{watkins1992QLearning,
    author = {Watkins, Christopher and Dayan, Peter},
    year = {1992},
    month = {05},
    pages = {279-292},
    title = {Technical Note: Q-Learning},
    volume = {8},
    journal = {Machine Learning},
    doi = {10.1007/BF00992698}
}
@inproceedings{BagnellPolicySearch2003,
    author={J. Andrew Bagnell and Jeff G. Schneider},
    title={Covariant Policy Search},
    year={2003},
    cdate={1041379200000},
    pages={1019-1024},
    url={http://ijcai.org/Proceedings/03/Papers/146.pdf},
    booktitle={IJCAI},
    crossref={conf/ijcai/2003}
}
@misc{DDPG,
      title={Continuous control with deep reinforcement learning}, 
      author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
      year={2019},
      eprint={1509.02971},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{DQN,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei and Veness, Joel and Bellemare, Marc and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
year = {2015},
month = {02},
pages = {529-33},
title = {Human-level control through deep reinforcement learning},
volume = {518},
journal = {Nature},
doi = {10.1038/nature14236}
}

@article{DPG,
author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
year = {2014},
month = {06},
pages = {},
title = {Deterministic Policy Gradient Algorithms},
volume = {1},
journal = {31st International Conference on Machine Learning, ICML 2014}
}

@article{PPO,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{TRPO,
      title={Trust Region Policy Optimization}, 
      author={John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Pieter Abbeel},
      year={2017},
      eprint={1502.05477},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{ACER,
      title={Sample Efficient Actor-Critic with Experience Replay}, 
      author={Ziyu Wang and Victor Bapst and Nicolas Heess and Volodymyr Mnih and Remi Munos and Koray Kavukcuoglu and Nando de Freitas},
      year={2017},
      eprint={1611.01224},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

%
%
% METHOD
%
%
@book{shneydor1998Guidance,
    title={Missile Guidance and Pursuit: Kinematics, Dynamics and Control},
    author={Shneydor, N.A.},
    isbn={9781898563433},
    series={Horwood engineering science series},
    url={https://books.google.no/books?id=8X7CQgAACAAJ},
    year={1998},
    publisher={Horwood Pub.}
}
@book{Fossen2021,
    author = {Fossen, Thor Inge},
    year = {2021},
    pages = {},
    title = {Handbook of Marine Craft Hydrodynamics and Motion Control},
    isbn = {978-1-119-57505-4},
    journal = {Handbook of Marine Craft Hydrodynamics and Motion Control. 2nd. Edition, Wiley.},
}
@INPROCEEDINGS{Gazebo,
    author={Koenig, N. and Howard, A.},
    booktitle={2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)}, 
    title={Design and use paradigms for Gazebo, an open-source multi-robot simulator}, 
    year={2004},
    volume={3},
    number={},
    pages={2149-2154 vol.3},
    doi={10.1109/IROS.2004.1389727}
}
@Inbook{RotorS_Furrer2016,
    author="Furrer, Fadri
    and Burri, Michael
    and Achtelik, Markus
    and Siegwart, Roland",
    editor="Koubaa, Anis",
    chapter="RotorS---A Modular Gazebo MAV Simulator Framework",
    title="Robot Operating System (ROS): The Complete Reference (Volume 1)",
    year="2016",
    publisher="Springer International Publishing",
    address="Cham",
    pages="595--625",
    isbn="978-3-319-26054-9",
    doi="10.1007/978-3-319-26054-9_23",
    url="http://dx.doi.org/10.1007/978-3-319-26054-9_23"
}
@misc{baselines,
    author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
    title = {OpenAI Baselines},
    year = {2017},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/openai/baselines}},
}
@inproceedings{ROS,
    author="Quigley, Morgan
    and Gerkey, Brian
    and Conley, Ken 
    and Faust, Josh 
    and Foote, Tully 
    and Leibs, Jeremy 
    and Berger, Eric 
    and Wheeler, Rob 
    and Ng, Andrew",
    title="ROS: an open-source Robot Operating System",
    booktitle="Proc. of the IEEE Intl. Conf. on Robotics and Automation (ICRA)
    Workshop on Open Source Robotics",
    month = {05},
    year=2009,
    address="Kobe, Japan"
}
@misc{DLUnipd,
    author        = {Sperduti, Alessandro and Navarin, Nicolo},
    title         = {Lecture notes in Deep Learning},
    month         = {4},
    year          = {2021},
    publisher={Università degli Studi di Padova}
}
@misc{XAI,
    author        = {Strümke, Inga},
    title         = {Lecture notes; Neural Networks, Explainable Artificial                 Intelligence and Shapley Values},
    month         = {11},
    year          = {2021},
    publisher={Norwegian University of Science and Technology}
}

@inproceedings{bubeck2021aLawOfRobustness,
    author = {Bubeck, Sébastien and Sellke, Mark},
    title = {A Universal Law of Robustness via Isoperimetry},
    booktitle = {NeurIPS 2021},
    year = {2021},
    month = {12},
    abstract = {Classically, data interpolation with a parametrized model class is possible as long as the number of parameters is larger than the number of equations to be satisfied. A puzzling phenomenon in deep learning is that models are trained with many more parameters than what this classical theory would suggest. We propose a theoretical explanation for this phenomenon. We prove that for a broad class of data distributions and model classes, overparametrization is necessary if one wants to interpolate the data smoothly. Namely we show that smooth interpolation requires d times more parameters than mere interpolation, where d is the ambient data dimension. We prove this universal law of robustness for any smoothly parametrized function class with polynomial size weights, and any covariate distribution verifying isoperimetry. In the case of two-layers neural networks and Gaussian covariates, this law was conjectured in prior work by Bubeck, Li and Nagaraj. We also give an interpretation of our result as an improved generalization bound for model classes consisting of smooth functions.},
    url = {https://www.microsoft.com/en-us/research/publication/a-universal-law-of-robustness-via-isoperimetry/},
}
@inproceedings{Chen2016DRQN,
    title={Deep Q-Learning with Recurrent Neural Networks},
    author={C.L.P. Chen},
    year={2016}
}

%
%
% RESULTS AND DISCUSSION
%
%
@misc{ImageNet1Hour,
      title={Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour}, 
      author={Priya Goyal and Piotr Dollár and Ross Girshick and Pieter Noordhuis and Lukasz Wesolowski and Aapo Kyrola and Andrew Tulloch and Yangqing Jia and Kaiming He},
      year={2018},
      eprint={1706.02677},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{dontdecayLRIncreaseBatch,
      title={Don't Decay the Learning Rate, Increase the Batch Size}, 
      author={Samuel L. Smith and Pieter-Jan Kindermans and Chris Ying and Quoc V. Le},
      year={2018},
      eprint={1711.00489},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{batchsizeInvariance,
      title={Batch size-invariance for policy optimization}, 
      author={Jacob Hilton and Karl Cobbe and John Schulman},
      year={2021},
      eprint={2110.00641},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@Book{DeepLearningBook,
  Title                    = {Deep Learning},
  Author                   = {Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
  Publisher                = {MIT Press},
  Year                     = {2016},

  Address                  = {Cambridge, MA, USA},
  Note                     = {\url{http://www.deeplearningbook.org}}
}
@misc{selftuningAC,
      title={A Self-Tuning Actor-Critic Algorithm}, 
      author={Tom Zahavy and Zhongwen Xu and Vivek Veeriah and Matteo Hessel and Junhyuk Oh and Hado van Hasselt and David Silver and Satinder Singh},
      year={2021},
      eprint={2002.12928},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

%
%
% IMPROVEMENTS
%
%

@article{D4PG,
  author    = {Gabriel Barth{-}Maron and
               Matthew W. Hoffman and
               David Budden and
               Will Dabney and
               Dan Horgan and
               Dhruva TB and
               Alistair Muldal and
               Nicolas Heess and
               Timothy P. Lillicrap},
  title     = {Distributed Distributional Deterministic Policy Gradients},
  journal   = {CoRR},
  volume    = {abs/1804.08617},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.08617},
  eprinttype = {arXiv},
  eprint    = {1804.08617},
  timestamp = {Mon, 13 Aug 2018 16:48:29 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-08617.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}